{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "В этой задаче мы научимся строить решающие деревья с нуля. Это несложный, но распространённый алгоритм машинного обучения. Деревья применяются для решения задач регрессии, классификации, аплифт-моделирования и ранжирования.\n",
    "\n",
    "Решающие деревья – составной элемент в ансамблях моделей: случайный лес, градиентный бустинг.\n",
    "\n",
    "Решающие деревья реализованы во многих популярных библиотеках. Однако ничто не может быть лучшим знакомством с ними и с механизмом их работы, как возможность один раз написать решающее дерево самому. Понимание этих принципов поможет как в реальной работе, так и на собеседованиях – особенно в случаях, когда речь пойдет о принципах работы упомянутого градиентного бустинга."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f27fc5ccca1bfd7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Что такое решающее дерево?\n",
    "Решающее дерево – это бинарное дерево, в узлах которого содержатся условия вида \"возраст < 30\" (для численных признаков) или \"пол = мужской\" (для категориальных), а в листьях предсказание модели (класс в случае классификации или численное значение в случае регрессии). "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2dde0a60b4e6c39"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Задача регрессии\n",
    "Мы будем предсказывать количество дней просрочки. Клиент подает заявку на кредит, указывает ряд данных о себе, а также сумму и срок кредита. Наша задача предсказать количество дней просрочки. Для большинства клиентов это значение равно 0 дней. Но для некоторых клиентов это значение больше нуля. Чем выше прогнозное значение \"дней просрочки\", тем более рискованно для банка одобрить заявку на кредит.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a77a8553b27607a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для обучения алгоритма у нас есть размеченный датасет с заявками на кредит. Целевая переменная — delay_days. Наша задача обучить модель (решающее дерево), которая для новых клиентов будет предсказывать количество дней просрочки, чтобы среднеквадратичная ошибка была минимальной."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdbbf3e6272462a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Дерево строится по данным обучающей выборки, на которой мы знаем значение признаков и целевую переменную для каждого объекта. Затем на новых данных с помощью построенного дерева выполняется предсказание целевой переменной, как мы это делали для примера с Андреем и Петром. Только вместо \"одобрить/ не одобрить\" мы будем предсказывать количество дней."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54b663f4c06ffa5b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "```sql\n",
    "SELECT\n",
    "    age,\n",
    "    income,\n",
    "    dependents,\n",
    "    has_property,\n",
    "    has_car,\n",
    "    credit_score,\n",
    "    job_tenure,\n",
    "    has_education,\n",
    "    loan_amount,\n",
    "    dateDiff('day', loan_start, loan_deadline) AS loan_period,\n",
    "    CASE\n",
    "        WHEN loan_payed > loan_deadline\n",
    "        THEN dateDiff('day', loan_deadline, loan_payed)\n",
    "        ELSE 0\n",
    "    END AS delay_days\n",
    "FROM\n",
    "    default.loan_delay_days\n",
    "ORDER BY\n",
    "    id;\n",
    "\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c1c1c55c02fe872"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Информационный критерий\n",
    "Информационный критерий — это метод оценки качества разбиения данных на две или более группы в решающем дереве. Это условие, по которому мы выбираем оптимальное разбиение данных в каждом узле дерева. Хороший информационный критерий помогает выбрать такой вариант разбиения выборки на две подвыборки, чтобы ветвление дерева наиболее осмысленно разбивало данные."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7de2c4a39eb16a29"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Предсказание в задаче регрессии выполняется по среднему значению целевой переменной всех объектов, попавших в лист на этапе обучения. В первом примере среднее значение для листа слева и среднее значение для листа справа будет ближе к истинным значениям. Во втором примере среднее значение будет дальше."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aab5007ec37ebd69"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Критерий разбиения\n",
    "Для задач регрессии в качестве критерия разбиения обычно используется MSE (Mean Squared Error). MSE – это средний квадрат ошибки (разницы) между фактическими значениями целевой переменной и предсказанными. Мы считаем MSE до разбиения и после. То разбиение, которое даст наибольшее снижение ошибки – оптимальное."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2dac2fc8af84f89d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для выбора варианта разбиения оценивают средневзвешенное значение критерия в обоих выборках. Если средневзвешенное значение критерия в выборках слева и справа лучше, значит разбиение хорошее."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60c644eb4da82088"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Задание\n",
    "Реализуйте две функции:\n",
    "\n",
    "mse – принимает на вход вектор значений, возвращает значение mse.\n",
    "weighted_mse – принимает на вход два вектора значений (слева и справа) и возвращает средневзвешенную mse."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "302451c48448e3cb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "MSE – это ошибка между истинными значениями и предсказанными. Как мы разобрали выше, предсказание в задаче регрессии – это среднее целевой переменной для всех объектов узла. \n",
    "\n",
    "Поэтому в качестве предсказанного значения вычислите среднее значение выборки. И найдите MSE между истинными значениями выборки и предсказанным (средним)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bf7c0d413e5e149"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mse(y: np.ndarray) -> float:\n",
    "    \"\"\"Compute the mean squared error of a vector.\"\"\"\n",
    "    y_mean = np.mean(y)\n",
    "    return np.mean((y - y_mean) ** 2)\n",
    "\n",
    "\n",
    "def weighted_mse(y_left: np.ndarray, y_right: np.ndarray) -> float:\n",
    "    \"\"\"Compute the weighted mean squared error of two vectors.\"\"\"\n",
    "    mse_left = mse(y_left)\n",
    "    mse_right = mse(y_right)\n",
    "    total_len = len(y_left)+len(y_right)\n",
    "    return (mse_left*len(y_left)+mse_right*len(y_right))/total_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Сплит по одному признаку\n",
    "Датасет подготовлен. Информационный критерий считать умеем. \n",
    "\n",
    "Теперь научимся определять, какой сплит (разбиение) будет оптимальным. На этом шаге мы делаем сплит только по одному признаку. Выбираем такое значение признака, чтобы средневзвешенный MSE был минимальынм."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eec3252961a051fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Задание\n",
    "Реализуйте функцию split. Функция принимает на вход выборку (матрицу признаков X и вектор целевой переменной y) и индекс признака. Возвращает значение порога с наилучшим разбиением.\n",
    "\n",
    "Например, если разбиение выполняется по полю age, в качестве аргумента feature будет передано значение 0. В качестве результата может быть значение 42. Что значит, что все объекты с age <= 42.0 попадают в левую выборку, остальные в правую выборку."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aeb561fdd6c62252"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Перебираем все значения признака:\n",
    "\n",
    "    Разделяем данные по порог -> подвыборка слева, подвыборка справа\n",
    "        Считаем взвешенный критерий для подвыборок слева и справа\n",
    "Возвращаем значение порога, который дает минимальное значение взвешенного критерия\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71cf56b84adaf006"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def split(X: np.ndarray, y: np.ndarray, feature: int) -> float:\n",
    "    \"\"\"Find the best split for a node (one feature)\"\"\"\n",
    "    my_x = X[:, feature]\n",
    "    best_threshold = None\n",
    "    min_mse = float('inf')\n",
    "\n",
    "    for x in np.unique(my_x):\n",
    "        left_mask = my_x <= x\n",
    "        right_mask = my_x > x\n",
    "        \n",
    "        y_left = y[left_mask]\n",
    "        y_right = y[right_mask]\n",
    "        \n",
    "        mse_ = weighted_mse(y_left, y_right)\n",
    "        \n",
    "        if mse < min_mse:\n",
    "            min_mse = mse\n",
    "            best_threshold = x\n",
    "\n",
    "    return best_threshold"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-08T19:08:05.115693200Z",
     "start_time": "2024-10-08T19:08:04.733925600Z"
    }
   },
   "id": "3fa00d3f8af8b345"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Сплит по всем признакам\n",
    "Отлично, мы научились разбивать выборку на две подвыборки по одному признаку, выбирая значения признака таким образом, чтобы минимизировать средневзвешенный критерий MSE.\n",
    "\n",
    "Теперь сделаем то же самое, но для всех признаков. Ваша задача — найти наилучший сплит среди всех признаков."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8290a82f1564d07"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Задание\n",
    "Реализуйте функцию best_split. Функция принимает на вход выборку (матрицу признаков X и вектор целевой переменной y). Возвращает индекс признака и значение порога с наилучшим разбиением."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34fa08b5ed6a0d74"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def best_split(X: np.ndarray, y: np.ndarray) -> tuple[int, float]:\n",
    "    \"\"\"Find the best split for a node (one feature)\"\"\"\n",
    "    bests = {}\n",
    "    \n",
    "    for i in range(X.shape[1]): \n",
    "        bests[i] = split(X, y, i)\n",
    "        \n",
    "    best_threshold = min(bests.values())  \n",
    "    best_feature = min(bests, key=bests.get)  \n",
    "\n",
    "    return best_feature, best_threshold"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e4479486f40259f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь реализуем класс Node. Это вспомогательный класс. Каждый экземпляр класса описывает отдельный узел или лист в дереве. Из этих нод мы и будем строить дерево."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3708d1edb7ff2c3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Давайте подумаем, какие атрибуты и каких типов необходимо добавить для класса Node:\n",
    "\n",
    "feature – индекс признака, по которому выборка, попавшая в ноду, разделяется на 2 дочерние ноды. Тип: int\n",
    "threshold – значение порога. Все элементы, у которых значение признака feature <= threshold, попадают в левую дочернюю ноду. Остальные в правую дочернюю ноду. Тип: float\n",
    "n_samples – количество объектов в ноде. Тип: int\n",
    "value – среднее значение целевой переменной среди всех объектов в ноде, округленное до целого. Тип: int\n",
    "mse – значение критерия MSE в ноде. Тип: float\n",
    "left – левая дочерняя нода. Тип: Node\n",
    "right – правая дочерняя нода. Тип: Node\n",
    "Для листьев также будем использовать класс Node. Только поля feature, threshold, left, right не будут заполнены."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21a2b1f8b4f8fbcf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Задание\n",
    "Вам дана заготовка класса Node с тремя заполненными атрибутами. Завершите класс полностью, добавив все оставшиеся атрибуты.\n",
    "\n",
    "Обратите внимание, что класс Node мы реализуем как датакласс. Это более удобная и компактная запись. Если вам не требуется реализовывать дополнительную логику при инициализации экземпляра класса, то используйте датаклассы. Ваш код будет выглядет более читабельным. Подробнее о датаклассах можно почитать по ссылке.\n",
    "\n",
    "Для всех атрибутов укажите значение None в качестве дефолтного. Кажется, для числовых атрибутов это выглядит странным и можно использовать дефолтный 0. Но дефолтный 0 может совпасть с значением индекса признака, значением порога или mse. Поэтому более универсально для не заполненных значений использовать None. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5932127adfcf6eda"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    A node in a decision tree.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature : int, optional (default=None)\n",
    "        The feature index used for splitting the node.\n",
    "    threshold : float, optional (default=None)\n",
    "        The threshold value at the node.\n",
    "    n_samples : int, optional (default=None)\n",
    "        The number of samples at the node.\n",
    "    value : int, optional (default=None)\n",
    "        The value of the node (i.e., the mean target value of the samples at the node).\n",
    "    mse : float, optional (default=None)\n",
    "        The mean squared error of the node (i.e., the impurity criterion).\n",
    "    left : Node, optional (default=None)\n",
    "        The left child node.\n",
    "    right : Node, optional (default=None)\n",
    "        The right child node.\n",
    "    \"\"\"\n",
    "       \n",
    "    feature: int = None\n",
    "    threshold: float = None\n",
    "    n_samples: int = None\n",
    "    value: int = None\n",
    "    mse: float = None\n",
    "    left: Node = None\n",
    "    right: Node = None\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-09T18:43:03.936936200Z",
     "start_time": "2024-10-09T18:43:03.930180600Z"
    }
   },
   "id": "20ef5878e1475861"
  },
  {
   "cell_type": "markdown",
   "source": [
    "DecisionTreeRegressor\n",
    "Подведем промежуточный итог, чему мы уже научились:\n",
    "\n",
    "1. Считать информационный критерий и взвешенный критерий, чтобы оценить качество сплита.\n",
    "2. Находить наилучшее разбиение выборки.\n",
    "3. Определили сущность нода и описали ее классом Node.\n",
    "# Пора переходить к построению дерева."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5a8c30c8f1ed2d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Как строится дерево?\n",
    "Для построение дерева используется рекурсивный алгоритм. Корневая нода делится на две дочерние ноды. Каждая дочерняя нода в свою очередь делится еще на две дочерние ноды. Деление продолжается, пока не будет достигнут критерий остановки. В рекурсивных алгоритмах это еще называется базовый случай."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca87e738290db591"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Разделить_ноду (Node):\n",
    "    Если достигли критерия остановки, то останавливаемся.\n",
    "    Ищем лучшее разбиение:\n",
    "        Если нашли лучшее разбиение, разбиваем Node на две дочерние Left и Right:\n",
    "            Разделить_ноду(Left)\n",
    "            Разделить_ноду(Right)\n",
    "        Иначе останавливаемся.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52bd9eb503e8aa98"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Критерии остановки\n",
    "На практике используется много критериев остановки. Мы реализуем только два:\n",
    "\n",
    "- max_depth (максимальная глубина дерева) — если достигли максимальной глубины, нода дальше не делится и остается листом.\n",
    "- min_samples_split (минимальное число объектов в ноде для дальнейшего деления) — если объектов меньше, нода дальше не делится и остается листом."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f72fb41e10b471a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Depth-wise подход\n",
    "В этой задаче мы используется подход построения дерева, который называется depth-wise (в глубину). Его идея в том, что каждая нода делится независимо до тех пор, пока не будет достигнут один из критериев остановки. Дерево очень быстро растет в глубину. Причем растет достаточно равномерно. Такой подход по умолчанию используется, например, при построении деревьев в популярной библиотеке XGBoost."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c51afbb4bf4cbe43"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Задание\n",
    "Реализуйте класс DecisionTreeRegressor.\n",
    "\n",
    "Метод fit — это публичный метод класса (api класса). Он предназначен для использования внешним кодом, который создает экземпляры класса и манипулируют ими.\n",
    "\n",
    "Методы, названия которых начинаются с символа \"_\", называются внутренними методами. Они реализуют внутреннюю логику класса и не предназначены для использования снаружи.\n",
    "\n",
    "Перенесите код из реализованных ранее функций: mse, weighted_mse, best_split в одноименные внутренние методы. Перенести класс Node.\n",
    "\n",
    "Реализуйте внутренний метод _split_node"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea0ef92ca459cfea"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import json\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    A node in a decision tree.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature : int, optional (default=None)\n",
    "        The feature index used for splitting the node.\n",
    "    threshold : float, optional (default=None)\n",
    "        The threshold value at the node.\n",
    "    n_samples : int, optional (default=None)\n",
    "        The number of samples at the node.\n",
    "    value : int, optional (default=None)\n",
    "        The value of the node (i.e., the mean target value of the samples at the node).\n",
    "    mse : float, optional (default=None)\n",
    "        The mean squared error of the node (i.e., the impurity criterion).\n",
    "    left : Node, optional (default=None)\n",
    "        The left child node.\n",
    "    right : Node, optional (default=None)\n",
    "        The right child node.\n",
    "    \"\"\"\n",
    "\n",
    "    feature: int = None\n",
    "    threshold: float = None\n",
    "    n_samples: int = None\n",
    "    value: int = None\n",
    "    mse: float = None\n",
    "    left: Node = None\n",
    "    right: Node = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DecisionTreeRegressor:\n",
    "    \"\"\"Decision tree regressor.\"\"\"\n",
    "    max_depth: int\n",
    "    min_samples_split: int = 2\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> DecisionTreeRegressor:\n",
    "        \"\"\"Build a decision tree regressor from the training set (X, y).\"\"\"\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.tree_ = self._split_node(X, y)\n",
    "        return self\n",
    "\n",
    "    def _mse(self, y: np.ndarray) -> float:\n",
    "        \"\"\"Compute the mse criterion for a given set of target values.\"\"\"\n",
    "        return np.mean((y - np.mean(y)) ** 2)\n",
    "\n",
    "    def _weighted_mse(self, y_left: np.ndarray, y_right: np.ndarray) -> float:\n",
    "        \"\"\"Compute the weighted mse criterion for two given sets of target values.\"\"\"\n",
    "        if y_left.size == 0 or y_right.size == 0:\n",
    "            return float('inf')\n",
    "        num = self._mse(y_left) * y_left.size + self._mse(y_right) * y_right.size\n",
    "        den = y_left.size + y_right.size\n",
    "        return num / den\n",
    "\n",
    "    def _best_split(self, X: np.ndarray, y: np.ndarray) -> tuple[int, float]:\n",
    "        \"\"\"Find the best split for a node.\"\"\"\n",
    "        node_size = y.size\n",
    "        if node_size < self.min_samples_split:\n",
    "            return None, None\n",
    "        node_mse = self._mse(y)\n",
    "        best_mse = node_mse\n",
    "        best_idx, best_thr = None, None\n",
    "        for idx in range(self.n_features_):\n",
    "            thresholds = np.unique(X[:, idx])\n",
    "            for thr in thresholds:\n",
    "                left = y[X[:, idx] <= thr]\n",
    "                right = y[X[:, idx] > thr]\n",
    "\n",
    "                if left.size == 0 or right.size == 0:\n",
    "                    continue\n",
    "\n",
    "                weighted_mse = self._weighted_mse(left, right)\n",
    "                if weighted_mse < best_mse:\n",
    "                    best_mse = weighted_mse\n",
    "                    best_idx = idx\n",
    "                    best_thr = thr\n",
    "\n",
    "        return best_idx, best_thr\n",
    "\n",
    "    def _split_node(self, X: np.ndarray, y: np.ndarray, depth: int = 0) -> Node:\n",
    "        \"\"\"Split a node and return the resulting left and right child nodes.\"\"\"\n",
    "        if depth == self.max_depth or y.size < self.min_samples_split:\n",
    "            return Node(value=int(round(np.mean(y))), mse=self._mse(y), n_samples=y.size)\n",
    "\n",
    "        best_idx, best_thr = self._best_split(X, y)\n",
    "        if best_thr is None:\n",
    "            return None\n",
    "\n",
    "        left_idx = X[:, best_idx] <= best_thr\n",
    "        right_idx = X[:, best_idx] > best_thr\n",
    "\n",
    "        left_child = self._split_node(X[left_idx], y[left_idx], depth + 1)\n",
    "        right_child = self._split_node(X[right_idx], y[right_idx], depth + 1)\n",
    "\n",
    "        return Node(feature=best_idx, threshold=best_thr, n_samples=y.size, left=left_child, right=right_child,\n",
    "                    value=int(round(np.mean(y))),\n",
    "                    mse=self._mse(y))\n",
    "    def as_json(self) -> str:\n",
    "        \"\"\"Return the decision tree as a JSON string.\"\"\"\n",
    "        return json.dumps(self._as_json(self.tree_), indent=4)\n",
    "\n",
    "    def _as_json(self, node: Node) -> dict:\n",
    "        if node is None:\n",
    "            return None  # JSON-совместимая строка для None\n",
    "\n",
    "        if node.left is None and node.right is None:\n",
    "            return {\n",
    "                'value': int(node.value) if node.value is not None else None,\n",
    "                'n_samples': int(node.n_samples) if node.n_samples is not None else None,\n",
    "                'mse': round(float(node.mse), 2) if node.mse is not None else None\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            'feature': int(node.feature) if node.feature is not None else None,\n",
    "            'threshold': int(node.threshold) if node.threshold is not None else None,\n",
    "            'n_samples': int(node.n_samples) if node.n_samples is not None else None,\n",
    "            'mse': round(float(node.mse), 2) if node.mse is not None else None,\n",
    "            'left': self._as_json(node.left),\n",
    "            'right': self._as_json(node.right)\n",
    "        }\n",
    "    def _predict_one_sample(self, features: np.ndarray) -> int:\n",
    "        \"\"\"Predict the target value of a single sample.\"\"\"\n",
    "        node = self.tree_\n",
    "        while node.left or node.right:\n",
    "            if features[node.feature] <= node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.value\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "    Predict regression target for X.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        The input samples.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : array of shape (n_samples,)\n",
    "        The predicted values.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "        return np.array([self._predict_one_sample(sample) for sample in X])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-13T15:27:06.400686800Z",
     "start_time": "2024-10-13T15:27:06.391168200Z"
    }
   },
   "id": "999df55fdcfafbd5"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a8b176b956d00754"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"feature\": 0,\n",
      "    \"threshold\": 18.0,\n",
      "    \"n_samples\": 10,\n",
      "    \"value\": 6,\n",
      "    \"mse\": 162.85,\n",
      "    \"left\": {\n",
      "        \"feature\": null,\n",
      "        \"threshold\": null,\n",
      "        \"n_samples\": 1,\n",
      "        \"value\": 43,\n",
      "        \"mse\": 0.0,\n",
      "        \"left\": \"null\",\n",
      "        \"right\": \"null\"\n",
      "    },\n",
      "    \"right\": {\n",
      "        \"feature\": 6,\n",
      "        \"threshold\": 6.0,\n",
      "        \"n_samples\": 9,\n",
      "        \"value\": 2,\n",
      "        \"mse\": 16.469135802469136,\n",
      "        \"left\": {\n",
      "            \"feature\": null,\n",
      "            \"threshold\": null,\n",
      "            \"n_samples\": 1,\n",
      "            \"value\": 12,\n",
      "            \"mse\": 0.0,\n",
      "            \"left\": \"null\",\n",
      "            \"right\": \"null\"\n",
      "        },\n",
      "        \"right\": {\n",
      "            \"feature\": 8,\n",
      "            \"threshold\": 120887.0,\n",
      "            \"n_samples\": 8,\n",
      "            \"value\": 1,\n",
      "            \"mse\": 5.6875,\n",
      "            \"left\": {\n",
      "                \"feature\": null,\n",
      "                \"threshold\": null,\n",
      "                \"n_samples\": 1,\n",
      "                \"value\": 7,\n",
      "                \"mse\": 0.0,\n",
      "                \"left\": \"null\",\n",
      "                \"right\": \"null\"\n",
      "            },\n",
      "            \"right\": {\n",
      "                \"feature\": null,\n",
      "                \"threshold\": null,\n",
      "                \"n_samples\": 7,\n",
      "                \"value\": 0,\n",
      "                \"mse\": 1.1020408163265307,\n",
      "                \"left\": \"null\",\n",
      "                \"right\": \"null\"\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([\n",
    "    [76, 32181, 3, 0, 1, 814, 28, 1, 142434, 1770],\n",
    "    [69, 52789, 8, 1, 0, 501, 28, 1, 120887, 1590],\n",
    "    [19, 70535, 1, 0, 1, 325, 26, 1, 188766, 810],\n",
    "    [31, 85271, 1, 0, 1, 525, 29, 1, 406792, 330],\n",
    "    [18, 19974, 2, 0, 1, 618, 34, 1, 155240, 1560],\n",
    "    [51, 74128, 3, 0, 1, 551, 14, 0, 257944, 420],\n",
    "    [67, 34922, 10, 1, 1, 657, 19, 0, 207532, 240],\n",
    "    [27, 54154, 1, 0, 1, 740, 38, 1, 229763, 660],\n",
    "    [61, 76998, 8, 0, 0, 869, 35, 1, 147957, 90],\n",
    "    [61, 41396, 5, 0, 0, 636, 6, 0, 483916, 120]\n",
    "])\n",
    "\n",
    "y_train = np.array([0, 7, 0, 0, 43, 0, 3, 0, 0, 12])  # Целевая переменная - 'delay_days'\n",
    "\n",
    "tree = DecisionTreeRegressor(max_depth=3)\n",
    "tree.fit(X_train, y_train)\n",
    "print(tree.as_json())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-13T12:38:39.290533400Z",
     "start_time": "2024-10-13T12:38:39.279022800Z"
    }
   },
   "id": "4e3cfa42b22ce435"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Визуализация дерева\n",
    "Дерево построили, теперь визуализируем его. Будет полезно визуально посмотреть, какое дерево у нас получилось. Особенно для глубоких деревьев."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7a3b8c1dd395a5e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Задание\n",
    "Вам необходимо реализовать метод as_json(). Метод переводит дерево в строку в формате JSON."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fa7a2c0cec7039d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Алгоритм отображения дерева в JSON формате тоже будет рекурсивным. Он аналогичен алгоритму построения дерева. Поэтому удобно будет реализовать еще один внутренний метод, например, _as_json(), который будет вызываться рекурсивно."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92019a3ce447ec42"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сформировать_json (Node):\n",
    "    Если это лист, формируем json для листа.\n",
    "        Останавливаемся.\n",
    "    Иначе\n",
    "        Формируем json для текущей ноды\n",
    "        Сформировать_json (Left)\n",
    "        Сформировать_json (Right)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea341dda7953994b"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def as_json(self) -> str:\n",
    "    \"\"\"Return the decision tree as a JSON string.\"\"\"\n",
    "    return json.dumps(self._as_json(self.tree_), indent=4)\n",
    "\n",
    "def _as_json(self, node: Node) -> dict:\n",
    "    if node is None:\n",
    "        return None  # JSON-совместимая строка для None\n",
    "\n",
    "    if node.left is None and node.right is None:\n",
    "        return {\n",
    "                'value': int(node.value) if node.value is not None else None,\n",
    "                'n_samples': int(node.n_samples) if node.n_samples is not None else None,\n",
    "                'mse': round(float(node.mse), 2) if node.mse is not None else None\n",
    "            }\n",
    "\n",
    "    return {\n",
    "            'feature': int(node.feature) if node.feature is not None else None,\n",
    "            'threshold': int(node.threshold) if node.threshold is not None else None,\n",
    "            'n_samples': int(node.n_samples) if node.n_samples is not None else None,\n",
    "            'mse': round(float(node.mse), 2) if node.mse is not None else None,\n",
    "            'left': self._as_json(node.left),\n",
    "            'right': self._as_json(node.right)\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-13T15:09:30.935860700Z",
     "start_time": "2024-10-13T15:09:30.919851500Z"
    }
   },
   "id": "a1651bc0dc670924"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "24951d8ca27b0740"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
